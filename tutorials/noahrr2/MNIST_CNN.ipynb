{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for building network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Libraries for dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Miscellaneous Libraries\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tutorial_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\" Initialize all layers of model \"\"\"\n",
    "        # CNN made from Learned Concepts from the Combination of ACM and Tutorial Provided\n",
    "        super(tutorial_model, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)\n",
    "        \n",
    "        self.conv2_dropout = nn.Dropout()                                                 \n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=320, out_features=200)\n",
    "        self.fc2 = nn.Linear(in_features=200, out_features=10)\n",
    "        # self.fc3 = nn.Linear(in_features=80, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\" Chain all layers together \"\"\"\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))          \n",
    "        \n",
    "        # Collapse 3D tensor to 1D\n",
    "        x = x.view(-1, 320)                            \n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        y = self.fc2(x)\n",
    "        # y = self.fc3(x)                                \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs for training\n",
    "num_epochs = 5           \n",
    "\n",
    "# Batch Size for training/testing\n",
    "batch_size = 64       \n",
    "\n",
    "# Learning Rate for optimizer\n",
    "learning_rate = 0.01     \n",
    "\n",
    "# Momentum for optimizer\n",
    "momentum = 0.5           \n",
    "\n",
    "# Dimensions of MNIST\n",
    "dim = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation for training data\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    transforms.ToTensor(),                            # Convert grayscale image to pytorch tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)),             # Normalize grayscale data\n",
    "])\n",
    "\n",
    "# Transformation for training data\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),                            # Convert grayscale image to pytorch tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)),             # Normalize grayscale data\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data\n",
    "trainset = torchvision.datasets.MNIST(root='./files', train=True, download=True, \n",
    "                                      transform=transform_train)\n",
    "\n",
    "# Initialize dataloader for training data\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, \n",
    "                                           num_workers=8)\n",
    "\n",
    "# Download testing Data\n",
    "testset = torchvision.datasets.MNIST(root='./files', train=False, download=False, \n",
    "                                     transform=transform_test)\n",
    "\n",
    "# Initialize dataloader for testing data\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, \n",
    "                                          num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize previously defined model\n",
    "model = tutorial_model()                                               \n",
    "\n",
    "# Definie loss function (Cross Entropy Loss)\n",
    "criterion = nn.CrossEntropyLoss()                                      \n",
    "\n",
    "# Initialize Optimizer (ADAM)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)     \n",
    "\n",
    "# Set model to training (updating weights)\n",
    "model.train();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Step: 1/938, Loss: 2.2982754707336426, Accuracy: 14.0625%\n",
      "Epoch: 1/5, Step: 101/938, Loss: 1.6123638153076172, Accuracy: 76.5625%\n",
      "Epoch: 1/5, Step: 201/938, Loss: 0.3458239734172821, Accuracy: 87.5%\n",
      "Epoch: 1/5, Step: 301/938, Loss: 0.21150200068950653, Accuracy: 93.75%\n",
      "Epoch: 1/5, Step: 401/938, Loss: 0.3421831727027893, Accuracy: 84.375%\n",
      "Epoch: 1/5, Step: 501/938, Loss: 0.1469740867614746, Accuracy: 98.4375%\n",
      "Epoch: 1/5, Step: 601/938, Loss: 0.30795836448669434, Accuracy: 92.1875%\n",
      "Epoch: 1/5, Step: 701/938, Loss: 0.20628461241722107, Accuracy: 95.3125%\n",
      "Epoch: 1/5, Step: 801/938, Loss: 0.22404170036315918, Accuracy: 95.3125%\n",
      "Epoch: 1/5, Step: 901/938, Loss: 0.2112247496843338, Accuracy: 96.875%\n",
      "Epoch: 2/5, Step: 1/938, Loss: 0.14998292922973633, Accuracy: 95.3125%\n",
      "Epoch: 2/5, Step: 101/938, Loss: 0.42787909507751465, Accuracy: 90.625%\n",
      "Epoch: 2/5, Step: 201/938, Loss: 0.247516930103302, Accuracy: 93.75%\n",
      "Epoch: 2/5, Step: 301/938, Loss: 0.13878120481967926, Accuracy: 96.875%\n",
      "Epoch: 2/5, Step: 401/938, Loss: 0.04703424125909805, Accuracy: 98.4375%\n",
      "Epoch: 2/5, Step: 501/938, Loss: 0.4404291808605194, Accuracy: 87.5%\n",
      "Epoch: 2/5, Step: 601/938, Loss: 0.15083499252796173, Accuracy: 93.75%\n",
      "Epoch: 2/5, Step: 701/938, Loss: 0.04918355867266655, Accuracy: 100.0%\n",
      "Epoch: 2/5, Step: 801/938, Loss: 0.07662630826234818, Accuracy: 96.875%\n",
      "Epoch: 2/5, Step: 901/938, Loss: 0.039473287761211395, Accuracy: 100.0%\n",
      "Epoch: 3/5, Step: 1/938, Loss: 0.08677828311920166, Accuracy: 95.3125%\n",
      "Epoch: 3/5, Step: 101/938, Loss: 0.1770179718732834, Accuracy: 93.75%\n",
      "Epoch: 3/5, Step: 201/938, Loss: 0.2508118152618408, Accuracy: 89.0625%\n",
      "Epoch: 3/5, Step: 301/938, Loss: 0.06965762376785278, Accuracy: 98.4375%\n",
      "Epoch: 3/5, Step: 401/938, Loss: 0.039413414895534515, Accuracy: 98.4375%\n",
      "Epoch: 3/5, Step: 501/938, Loss: 0.03360357508063316, Accuracy: 98.4375%\n",
      "Epoch: 3/5, Step: 601/938, Loss: 0.04190629720687866, Accuracy: 98.4375%\n",
      "Epoch: 3/5, Step: 701/938, Loss: 0.12235287576913834, Accuracy: 96.875%\n",
      "Epoch: 3/5, Step: 801/938, Loss: 0.04247669875621796, Accuracy: 98.4375%\n",
      "Epoch: 3/5, Step: 901/938, Loss: 0.17313101887702942, Accuracy: 95.3125%\n",
      "Epoch: 4/5, Step: 1/938, Loss: 0.07635942846536636, Accuracy: 96.875%\n",
      "Epoch: 4/5, Step: 101/938, Loss: 0.06744523346424103, Accuracy: 95.3125%\n",
      "Epoch: 4/5, Step: 201/938, Loss: 0.04796071723103523, Accuracy: 98.4375%\n",
      "Epoch: 4/5, Step: 301/938, Loss: 0.04440777003765106, Accuracy: 98.4375%\n",
      "Epoch: 4/5, Step: 401/938, Loss: 0.044026896357536316, Accuracy: 98.4375%\n",
      "Epoch: 4/5, Step: 501/938, Loss: 0.03156589716672897, Accuracy: 100.0%\n",
      "Epoch: 4/5, Step: 601/938, Loss: 0.09389893710613251, Accuracy: 98.4375%\n",
      "Epoch: 4/5, Step: 701/938, Loss: 0.017849164083600044, Accuracy: 100.0%\n",
      "Epoch: 4/5, Step: 801/938, Loss: 0.05529531463980675, Accuracy: 98.4375%\n",
      "Epoch: 4/5, Step: 901/938, Loss: 0.050671156495809555, Accuracy: 98.4375%\n",
      "Epoch: 5/5, Step: 1/938, Loss: 0.06028502807021141, Accuracy: 96.875%\n",
      "Epoch: 5/5, Step: 101/938, Loss: 0.09191292524337769, Accuracy: 98.4375%\n",
      "Epoch: 5/5, Step: 201/938, Loss: 0.03388252854347229, Accuracy: 100.0%\n",
      "Epoch: 5/5, Step: 301/938, Loss: 0.11115007847547531, Accuracy: 96.875%\n",
      "Epoch: 5/5, Step: 401/938, Loss: 0.06951037794351578, Accuracy: 98.4375%\n",
      "Epoch: 5/5, Step: 501/938, Loss: 0.016742633655667305, Accuracy: 100.0%\n",
      "Epoch: 5/5, Step: 601/938, Loss: 0.06278640031814575, Accuracy: 95.3125%\n",
      "Epoch: 5/5, Step: 701/938, Loss: 0.03287952393293381, Accuracy: 98.4375%\n",
      "Epoch: 5/5, Step: 801/938, Loss: 0.030942225828766823, Accuracy: 98.4375%\n",
      "Epoch: 5/5, Step: 901/938, Loss: 0.10253319889307022, Accuracy: 96.875%\n",
      "Run Time: 73.9451208114624\n"
     ]
    }
   ],
   "source": [
    "# Store time to calculate train time\n",
    "start_time = time.time()\n",
    "\n",
    "# Store loss and accuracy data\n",
    "loss = []\n",
    "accuracy = []\n",
    "\n",
    "# Train the model\n",
    "# Loop for number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    # Loop through data in batch sized increments\n",
    "    for batch_idx, (X_train_batch, Y_train_batch) in enumerate(train_loader):\n",
    "        # If trained on all data in epoch, move onto next epoch\n",
    "        if(Y_train_batch.shape[0]<batch_size):\n",
    "            continue\n",
    "\n",
    "        # Forward pass through network\n",
    "        output = model(X_train_batch)                           \n",
    "        # Calculate loss of predictions\n",
    "        curr_loss = criterion(output, Y_train_batch)            \n",
    "        # Store loss\n",
    "        loss.append(curr_loss.item())                           \n",
    "\n",
    "        \n",
    "        # Clear last calculation\n",
    "        optimizer.zero_grad()                                   \n",
    "        # Calculate gradient based on loss\n",
    "        curr_loss.backward()                                    \n",
    "        # Update model weights\n",
    "        optimizer.step()                                        \n",
    "\n",
    "        # Extract model predictions\n",
    "        _, predicted = torch.max(output.data, 1) \n",
    "        # Calculate number of correct predictions\n",
    "        correct = (predicted == Y_train_batch).sum().item()     \n",
    "        # Calculate/store accuracy\n",
    "        accuracy.append(correct/Y_train_batch.size(0))          \n",
    "        \n",
    "        # Intermitently print statistics\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Epoch: ' + str(epoch+1) + '/' + str(num_epochs) + ', Step: ' \n",
    "                  + str(batch_idx+1) + '/' + str(len(train_loader)) + ', Loss: ' \n",
    "                  + str(curr_loss.item()) + ', Accuracy: ' \n",
    "                  + str(correct/Y_train_batch.size(0)*100) + '%')\n",
    "\n",
    "# Store time to calculate train time\n",
    "end_time = time.time()\n",
    "\n",
    "# Print train time\n",
    "print('Run Time: ' + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.56%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# Set model to testing (constant weights)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Store number of correct/total samples in test data\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Loop through test data\n",
    "    for X_test_batch, Y_test_batch in test_loader:\n",
    "        # Forward pass through network\n",
    "        output = model(X_test_batch)  \n",
    "        \n",
    "        # Extract prediction\n",
    "        _, predicted = torch.max(output.data, 1)    \n",
    "        \n",
    "        # Update total number of sample\n",
    "        total += Y_test_batch.size(0)  \n",
    "        \n",
    "        # Update number of correct predictions\n",
    "        correct += (predicted == Y_test_batch).sum().item()     \n",
    "\n",
    "print('Test Accuracy: ' + str((correct/total) * 100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
